{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNgq2M9IVqoWheQ61qof2aX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bosunKwak/BigData/blob/main/text_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Overall Process\n",
        "<img width=\"380\" alt=\"스크린샷 2022-04-19 오후 11 29 44\" src=\"https://user-images.githubusercontent.com/87002218/164027812-736c6c74-e20b-4fcc-a057-dc2c1524d2c2.png\">\n"
      ],
      "metadata": {
        "id": "BeR26zdmNvsF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"here is the example\"\n",
        "1) Tokenize : here, is , the ,example\n",
        "- 문장을 토큰 시퀀스로 분석하는 과정\n",
        "- 토큰의 분리기준은 다를 수 있지만 문장을 구성하는 기본단위 -ex) 단어\n",
        "\n",
        "2) Vocabulary : 475, 21, 2, 30, 5297\n",
        "- 모은 단어의 토큰들을 합쳐 하나의 list를 만듦(어휘 집합 == 토크나이즈 수행 후 중복을 제거한 토큰들의 집합)\n",
        "- 각 단어를 문자 단위 ID 시퀀스로 변환하기 위해 사용\n",
        "\n",
        "3) Embedding : [[0.81,0.27,0.59], [ , , ], [ , , ], [ , , ]]\n",
        "- 컴퓨터는 인간이 사용하는 자연어를 있는 그대로 이해하는 것이 아니라 숫자를 계산\n",
        "- 사람이 쓰는 자연어를 기계가 이해할 수 잇는 숫자의 나열인 벡터로 바꾼 결과/ 일련의 과정 전체\n",
        "- 단어나 문장을 각각 벡터로 변환해 벡터 공간(vector space)로 끼워넣는다(embed) "
      ],
      "metadata": {
        "id": "_etOdQ8YO7YM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text classification\n",
        "- [pytorch를 이용해서 모델을 개발하는 전반적인 과정](https://github.com/bosunKwak/BigData/blob/main/overall_process.ipynb)을 text data를 가지고 실습\n",
        "- [tutorial 참고](https://pytorch.org/tutorials/beginner/text_sentiment_ngrams_tutorial.html)\n",
        "- data preparation & model development \n",
        "- [dataset](https://pytorch.org/text/stable/datasets.html#ag-news)"
      ],
      "metadata": {
        "id": "yqAVLBBBKTbL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Data Preparation"
      ],
      "metadata": {
        "id": "98x-FmrvX7xq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### - Access to the raw dataset iterators"
      ],
      "metadata": {
        "id": "_f-jFfHWwY-h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Zae3hlNOKLbg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "641966bf-ae0a-4b22-8f6b-abd650ecdeed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "29.5MB [00:00, 41.1MB/s]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torchtext.datasets import AG_NEWS\n",
        "train_iter = iter(AG_NEWS(split='train'))\n",
        "# iter : 순환 가능한 객체로 만드는 것"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next(train_iter)\n",
        "# 하나씩 꺼내옴"
      ],
      "metadata": {
        "id": "UJGR9b31SLd9",
        "outputId": "03e72aa7-db7a-43a3-b568-5e70d5575c41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3,\n",
              " 'Safety Net (Forbes.com) Forbes.com - After earning a PH.D. in Sociology, Danny Bazil Riley started to work as the general manager at a commercial real estate firm at an annual base salary of  #36;70,000. Soon after, a financial planner stopped by his desk to drop off brochures about insurance benefits available through his employer. But, at 32, \"buying insurance was the furthest thing from my mind,\" says Riley.')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "# tokenizer 선정 \n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "train_iter = AG_NEWS(split='train')\n",
        "\n",
        "# tokenizer 수행하는 함수\n",
        "def yield_tokens(data_iter):\n",
        "  # (category , text) : 뒤에 있는 text만 가져옴 \n",
        "    for _, text in data_iter:\n",
        "        yield tokenizer(text) # text를 tokenizer로 token화\n",
        "\n",
        "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=[\"<unk>\"]) # tokenize된 token들이 vocab에 들어오고, 새로운 단어의 경우 <unknown>처리\n",
        "vocab.set_default_index(vocab[\"<unk>\"]) # set_default_index : unknown 이라는 token을 index로 지정하겠다는 의미"
      ],
      "metadata": {
        "id": "NDUKcEwySb0k"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab.lookup_token(4)"
      ],
      "metadata": {
        "id": "SwNowDPPVKTM",
        "outputId": "e53aa6cb-d99b-4726-f069-7b8fe28c4f06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'to'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab(['here','is','an','example','to'])"
      ],
      "metadata": {
        "id": "vdC-kHgHVvia",
        "outputId": "d86f4596-fd70-4cb9-85d7-90544092a87f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[475, 21, 30, 5297, 4]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### - Prepare data processing pipelines\n",
        "text가 들어왔을 때, 이것을 어떻게 가공할 것인지에 대한 절차 정의"
      ],
      "metadata": {
        "id": "ni1u_PASXzJ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# text를 받았을 때 처리하는 pipeline\n",
        "text_pipeline = lambda x: vocab(tokenizer(x)) # x를 받아 tokenizer를 통해 토큰으로 바꾸고 다시 vocab으로\n",
        "\n",
        "# label 정보를 받았을 때 처리하는 pipeline\n",
        "label_pipeline = lambda x: int(x) - 1 # 1~4 -> 0~3"
      ],
      "metadata": {
        "id": "kf0d88hlYXq-"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_pipeline('here is an example')"
      ],
      "metadata": {
        "id": "WRO4RvGcY9up",
        "outputId": "0e170c22-b17e-46dc-86b6-5ddf31b6176e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[475, 21, 30, 5297]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### - Generate data batch and iterator\n"
      ],
      "metadata": {
        "id": "MsarJGz9ZK9K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "collate_fn \n",
        "- batch를 통해 collate_fn로 전달되면 데이터를 처리\n",
        "- collate : 종이를 순서에 맞춰서 정렬을 하는 것 \n"
      ],
      "metadata": {
        "id": "KkjNyASlZY1V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# batch : Dataloader에서 받아온 batch \n",
        "def collate_batch(batch):\n",
        "    label_list, text_list, offsets = [], [], [0] #offsets : 문장이 시작되는 지점 (첫번째 문장의 offset : 0 )\n",
        "    for (_label, _text) in batch:\n",
        "         label_list.append(label_pipeline(_label))\n",
        "         processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
        "         text_list.append(processed_text)\n",
        "         offsets.append(processed_text.size(0))\n",
        "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
        "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
        "    text_list = torch.cat(text_list)\n",
        "    return label_list.to(device), text_list.to(device), offsets.to(device)\n",
        "\n",
        "train_iter = AG_NEWS(split='train')\n",
        "dataloader = DataLoader(train_iter, batch_size=8, shuffle=False, collate_fn=collate_batch)"
      ],
      "metadata": {
        "id": "_tIBntFbZQzF"
      },
      "execution_count": 27,
      "outputs": []
    }
  ]
}